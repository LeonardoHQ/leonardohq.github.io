<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Project: Neural Network - Leonardo's Workspace</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Electrolize&family=JetBrains+Mono:wght@400;700&family=Space+Grotesk:wght@400;600&display=swap"
        rel="stylesheet">

    <link rel="stylesheet" href="css/style.css">
</head>

<body class="post-page">
    <main class="container">

        <a href="index.html" class="back-link">Volver al inicio</a>


        <article class="post-content">

            <header class="post-header">
                <span class="post-date">Leonardo Quiroga, February 23, 2026</span>
                <h1>Construyendo un Servidor MCP: versión 0.1</h1>
            </header>

            <p><strong>Este post fué escrito en su totalidad por un humano.</strong></code> </p>


            <img src="images/gandalf_computer.png" alt="Galdalf writing code" class="post-image">

            <p>
                No me considero la persona más entusiasmada por la IA. La primera vez que la usé fué en Diciembre de
                2022 a través de <a href="https://copilot.microsoft.com/" class="nav-contact">Copilot</a>. Mi primera
                expericiencia fué
                "escribiendo" tests en
                <a href="https://docs.python.org/3/library/unittest.html" class="nav-contact">unitest</a> y tengo el
                vívido recuerdo de mirar hacia el monitor y presenciar los primeros autocompletados dados por la
                herramienta. <br><br>

                En ese entonces no existía nada de lo que existe hoy, ni siquiera el concepto de
                <code> prompt engineer</code>.
                Mucho menos el concepto que vengo a exponer hoy, casi 4 años despues de que la IA se vuelva parte de
                mi vida y de la vida de prácticamente todos los desarrolladores.
            </p>

            <h2>Servidor MCP</h2>
            <p>
                Las siglas MCP significan <strong>Model Context Protocol</strong> y la palabra
                servidor, bueno, no creo que deba explicarla. Un servidor MCP es un proceso que
                se dedica a "servir" recursos a traves de un protocolo particular, similar a un servidor REST en
                intención pero no en sintaxis. Mientras que un servidor tradicional REST expone
                endpoints tales como <code>GET /customer</code>, un servidor MCP expone
                3 tipos de objetos: <strong>Tools, Resources</strong> y <strong>Prompts</strong>.
            </p>

            <p>
                Estos servidores tienen, a mi parecer, dos características principales:

            <ol>
                <li>Utilizan <a href="https://www.jsonrpc.org/" class="nav-contact">JSON-RCP</a>
                    para comunicarse con el cliente usando <code>stidio</code> o <code>stremeable HTTP</code> como <a
                        href="https://modelcontextprotocol.io/specification/2025-06-18/basic/transports"
                        class="nav-contact">
                        capas de transporte</a> </li>
                <li>Son amigables con los LLM.</li>
            </ol>
            </p>

            <p>
                Mientras que el punto uno es algo meramente técnico, el segundo es el más interesante:
                ¿Qué significa "amigable con un LLM"? ¿Toman mates juntos? ¿Son del mismo equipo de fútbol?
            </p>

            <p> Los LLM, al momento de ser entrenados, cuentan con el "conocimiento" (datos) que
                se le fué proporcionado a la fecha. Su "knowledge limit", generalmente de 3 a 6 meses previo a la
                fecha de su lanzamiento es todo lo que conocen. En los modelos iniciales, alla por 2022, ante
                cualquier pregunta de actualidad, la IA alucinaba y este es uno de los puntos principales de "amistad"
                entre los MCP y los LLM.
            </p>

            <p>
                <strong>Cuando conectamos un LLM a un servidor MCP le damos al modelo el contexto necesario para que
                    responda preguntas o accione ante un problema específico
                    de nuestro entorno. </strong> Para ello, dotamos al LLM de manos (tools),
                libros (resources) e instrucciones (prompts) para que sea capaz de realizar actividades
                para las cuales no fué entrenado originalmente. De eso se trata el proyecto de hoy.
            </p>


            <h2>El problema</h2>
            <p>
                Como todos, en mi día a día laboral me encuentro con actividades que no son completamente de mi agrado.
                Actualmente me desempeño como Tech Lead y una de mis tareas implica generar issues en Jira para que
                el equipo las implemente. Para generar una issue tengo que tener en cuenta varios puntos. El contenido
                debe:
            </p>

            <ol>
                <li>Ser lo suficientemente técnico para que no haya <em>(tanto)</em> lugar a la duda o ambigüedad.</li>
                <li>Tener en cuenta la interconexión entre sistemas, las capas que lo componen y la interacción entre
                    las mismas.</li>
                <li>Contener el suficiente contexto para que el programador no vaya a ciegas programando, sino que
                    entienda la razón por la que realiza los métodos y el problema que está resolviendo.</li>
                <li>En raras ocasiones debe contener una sección no técnica para que otros roles aprueben o verifiquen
                    que la funcionalidad es precisamente lo que se necesita.</li>
            </ol>

            <p>
                En resumen, quiero automatizar (o semi automatizar) la generación de issues de <em>buena calidad</em>
                haciendo
                uso de IA. Esta actividad sería excelente para que me pueda enfocar en otras
                cosas, agilizando el desarrollo <em>(o terminando desempleado)</em><br>
            </p>

            <h2>El contexto y sus formatos</h2>

            <p>El contexto de este problema abarca varios repositorios de código. Todos entre 40 y 50 mil LOC.
                En esta versión inicial estoy interesado en abarcar únicamente un repositorio.</p>

            <p>Para que el LLM sea capaz de entender el repositorio existen varias alternativas para almacenar la
                información</p>
            <ul>
                <li>Almacenamiento semántico basado en vectores</li>
                <li>Almacenamiento de grafos</li>
                <li>Almacenamiento híbrido de grafos y vectores</li>
                <li>Almacenamiento en base a... nada. Simplemente guardar el texto</li>
            </ul>

            <p>Por más que la última opción sea la más tentadora debido a la costumbre de simplemente generar
                prompts en herramientas como ChatGPT y Gemini, en realidad, es la alternativa menos eficiente.
                Los LLM tienen una ventana de contexto que es la cantidad de información medida en tokens que pueden
                procesar en una sola interacción.
            </p>
            <p>Si proporcionamos 40 mil LOC, la cantidad de tokens generados superará la ventana de contexto
                de la mayoría de LLMs dandonos como resultado las alucinaciones que queremos evitar. Por esa razón, la
                alternativa que decidí utilizar en este proyecto es el almacenamiento semántico basado en vectores.
            </p>

            <h3>Semántica y tree-sitter </h3>
            <p>Primero... ¿qué es el almacenamiento semántico? <br>
                Básicamente es el almacenamiento de información en base al <strong>significado</strong> en vez
                de únicamente al contenido. Vamos a un ejemplo
            </p>
            <pre><code>
class QueryTool:
    chroma_connection: ClientAPI = None

    def __init__(self) -> None:
        self.chroma_connection = ChromaSingleton()

    def query(self, query_term: str) -> QueryResult:
        """Queries the chroma collection with a query term and returns the results"""
        result = self.chroma_connection.get_or_create_collection("db").query(
            query_texts=[query_term],
            n_results=3,
            include=["documents", "metadatas", "distances", "embeddings"],
        )
        l.info(f"Query results for query term '{query_term}': {result}")
        return result
            </code></pre>

            <p>En el fragmento de código proporcinado vemos un montón de texto. Si alcenáramos la información tal cual
                fué
                presentada, un LLM tendría muchos tokens que procesar. Sería ideal entender qué representa cada segmento
                del "texto". Observandolo nuevamente distinguimos una clase principal <code>QueryTool</code>,
                dos métodos <code>__init__</code> y <code>query</code>, y un atributo de clase
                <code>chroma_connection</code>.
                Estas distinciones implican el análisis semántico <em>(muy simplificado)</em> de una pieza de código.
            </p>
            <p>Por suerte para realizar este tipo de análsis ya existen herramientas especializadas.
                Entre ellas
                una que destaca por su continuo uso en Github es <a href="https://tree-sitter.github.io/tree-sitter/"
                    class="nav-contact">tree-sitter</a>, un parseador de código incremental con el objetivo de
                "entender"
                cualquier lenguaje de programación. Generalmente usado para hacer syntax highlighting, posee muchos
                usos.
                En nuestro caso, nos interesa que sea capaz de ditinguir métodos y clases en Python.
            </p>
            <p>Tree-sitter es capaz de entender que <code>def query(self, query_term: str) -> QueryResult:</code> es
                un método, en qué línea de código inicia, en cual termina, a qué clase pertenece, cuales son sus
                argumentos,
                qué documentación posee el método, etc, etc, etc. Es la herramienta ideal para dividir un gran
                repositorio en <strong>chunks semánticos</strong>.</p>

            <h3>Vectorización</h3>
            <p>Recordando que estamos usando un <em>Almacenamiento semántico basado en vectores</em> ya tenemos mas o
                menos entendida la parte <em>semántica</em>. Ahora falta entender la parte de vectores. No voy a ahondar
                en
                explicaciones matemáticas de vectores principalmente porque no estoy capacitado para hacerlo. Pero
                tambien
                porque hacen perder el foco del post. Definamos un vector como un listado de números:
                <code>[0.1, 0.52, -0.35, 0.93]</code>. Cuando decimos que representamos datos como vectores lo que
                sucede es que, a partir del uso de una herramienta como
                <a href="https://docs.trychroma.com/docs/overview/getting-started" , class="nav-contact">chromadb</a>,
                tomamos
                como input el texto y como output se nos da vectores, simple.
            </p>
            <p>Luego, cuando queremos realizar una búsqueda tal como "connection to chroma", los términos tambien son
                transformados a vectores haciendo que la búsqueda sea algo como "qué tanto se parecen estos vectores a
                los
                vectores que tengo almacenados" y, de acuerdo a la similitud, un resultado se nos es proporcionado.
            </p>
            <h3>Chunks</h3>
            <p>Fusionando la separación semántica del código y luego convirtiendo los resultados en vectores nos da un
                excelente punto de partida para seccionar nuestra información en chunks. Los chunks son las piezas de un
                todo.
                En este proyecto almacené un registro vectorizado por cáda método de cada clase y un registro por cada
                definición
                de clase.
            </p>
            <img src="images/chunk_image.png" alt="Chunks" class="post-image">



        </article>
    </main>

</body>

</html>